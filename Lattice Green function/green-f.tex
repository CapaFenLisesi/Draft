% The entire content of this work (including the source code
% for TeX files and the generated PDF documents) by 
% Hongxiang Chen (nicknamed we.taper, or just Taper) is
% licensed under a 
% Creative Commons Attribution-NonCommercial-ShareAlike 4.0 
% International License (Link to the complete license text:
% http://creativecommons.org/licenses/by-nc-sa/4.0/).
\documentclass{article}

\usepackage{float}  % For H in figures
\usepackage{amsmath} % For math
\usepackage{amssymb}
\usepackage{mathrsfs}
\numberwithin{equation}{subsection} % have the enumeration go to the subsection level.
                                    % See:https://en.wikibooks.org/wiki/LaTeX/Advanced_Mathematics
\usepackage{graphicx}   % need for figures
\usepackage{cite} % need for bibligraphy.
\usepackage[unicode]{hyperref}  % make every cite a link
\usepackage{CJKutf8} % For Chinese characters
\usepackage{fancyref} % For easy adding figure,equation etc in reference. Use \fref or \Fref instead of \ref
\usepackage{braket} %http://tex.stackexchange.com/questions/214728/braket-notation-in-latex

% Following is for the special character: differential "d".
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
% Following is for theorems etc environments
% http://tex.stackexchange.com/questions/45817/theorem-definition-lemma-problem-numbering && https://en.wikibooks.org/wiki/LaTeX/Theorems
\usepackage{amsthm}
\newtheorem{defi}{Definition}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{coro}{Corollary}[section]
\theoremstyle{definition}
\newtheorem{ex}{Example}[section]

\usepackage{xcolor} %For colourful math:http://tex.stackexchange.com/questions/21598/how-to-color-math-symbols

% To include PDF in higher version format.
\pdfoptionpdfminorversion=6

% A list of nomenclatures.
\usepackage{nomencl}
\makenomenclature

\title{(Tentative) Calculating Green Function}
% TODO give it a better name.
\date{\today}
\author{Taper}


\begin{document}


\maketitle
\abstract{
    This is a note for reading the paper \cite{dissertation}, and for 
    understanding the code produced from that file.
}
\tableofcontents

\section{Chapter 1 - Introductions}
\label{sec:Chapter_1_-_Introductions}
This chapter is really a nice introduction to the current fields of 
mesoscopic physics. The writing is clear and it traces the develpment 
of this field. It gives me a lucid and holistic historical account of 
both the important discoveries and motives behind them. I should 
find those marked regions on pdf inside this part very useful.

\section{Chapter 2 - 2 Landauer-Büttiker formalism}
\label{sec:Chapter_2_-_2_Landauer-Buttiker_formalism}

This chapter introduces the Landauer-Büttiker formalism for calculating the
transport properties. The typical setup is illustrated below:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{pics/{ch2.setup_for_L-B_formalism}.png}
    \caption{Setup for the Landauer-Büttiker formalism}
    %\label{fig:}
\end{figure}

In that formalism, the currents following through the leads have the following
expression:
\begin{align}
    \label{eq:ch1.Landauer-Buttiker_formula}
    I_p = \frac{-e}{h} \sum_q \int T_{qp}(E)\left( f_p(E)-f_q(E) \right)\diff E
\end{align}
where $T_{pq}$ is the transmission coefficients for electrons to go from
lead $q$ to lead $p$. This formula can be simplified/linearized into:
\begin{align}
    I_p = \frac{e^2}{h}\sum_q T_{pq}(E_F)(V_p-V_q)
\end{align}
An obvious advantage of Landauer-Büttiker formalism is that it makes the
dependence of $I_p$ on experimental setup explicit in the formula.

This chapter continue to discuss some time reversal symmetry (TR) properties 
of this formula, centring/centering around the coefficient $T_{pq}$.
But I am perplexed by that he, while discussing TR, mentions the
magnetic field $B$ and formulae like:
\begin{align}
    T_{12}(+B)= T_{12}(-B)
\end{align}
\nomenclature{confusion: TR and $B$}{\nomrefpage}

\section{Chapter 3 - Tight-binding model}
\label{sec:Chapter_3_Tight-binding_model}

Here in this chapter the author presents the fundamental Hamiltonian of
the system under consideration.
\marginpar{
    Given the formula mentioned in previous chapter, the Hamiltonian
    presented here seemed seemingly extraneous. Read the introduction
    here in chapter 4 to understand the underlying logic.
}

The process to obtain the Hamiltonian is discretization the Hamiltonian
in continuous case, quite the reverse of the first few chapters of
A. Zee's QFT in a Nutshell. It should be noted that "a site may represent 
a region containing many atoms", although "this region should be small 
compared to physically relevant quantities such as the Fermi wavelength".

  \subsection{3.1 Spin-degenerate system}
  \label{sec:3.1_Spin-degenerate_system}
  Here the general Hamiltonian, using tight-binding model, is
  mentioned:
  \begin{align}
      H = &\sum_{n,m} 
          \left( t^x_{nm}\ket{n+1,m}\bra{n,m}
              +t^y_{nm}\ket{n,m+1}\bra{n,m}+h.c.\right)\nonumber\\
          &+\sum_{n,m} \epsilon_{nm}\ket{n,m}\bra{n,m}
  \end{align}

  The important thing is to determine the coefficient $t$.
  In the absence of magnetic field, $t$ is give by:
  \begin{align}
      t^x_{nm}=t^y_{nm}=-t=-\frac{\hbar^2}{2m^* a^2}
  \end{align}
  When magnetic field is present, we effect a so called Peierls
  substitution to get $t$.
  \marginpar{
      The author points to a paper, saying that it contains a
      "lucid discussion on the physics" of Peierls substitution.
      This might be something worth reading.
  }
  The result is, using Landau gauge in one dimensional under a
  homogeneous magnetic field.
  \begin{align}
      t^x_{nm} =& -t e^{i2\pi (m-1) \Phi/\Phi_0} \\
      t^y_{nm} =& -t
  \end{align}

  When the magnetic field is inhomogeneous, it is generally difficult
  to choose a gauge to calculate analytically. The author uses a
  very intuitive discretization process to approach this problem.
  The process is best illustrated by just the following picture:
  \begin{figure}[H]
      \centering
      \includegraphics[width=0.8\linewidth]{pics/{ch3.not-uniform_magnetic_field}.png}
      \caption{Not uniform magnetic field}
      \label{fig:ch3-uniform_magnetic_field.png}
  \end{figure}

  Therefore, the result is something like:
  \begin{align}
      t^x_{nm}=-t e^{i2\pi\sum_{m'<m}\Phi_{nm'}/\Phi_0}
  \end{align}
  \subsection{3.2 Including spin degrees of freedom}
  \label{sec:3.2_Including_spin_degrees_of_freedom}
  
  When the spin is taken into consideration, the formulation should
  be modified accordingly.

  If Zeeman/exchange splitting is considered, then:
  \begin{align}
      H_S = -\frac{1}{2}g^* \mu_B
          \sum_{nm}\ket{n,m}\bra{n,m}\otimes (B^{eff}_{nm}\cdot\sigma)
  \end{align}
  Not that the magnetic field strength here is only "effective".

  If Spin-orbit coupling is taken into consideration,
  \footnote{
      In my opinion, this is essentially all about Spin-Magnetic 
      field coupling, not just Spin-Orbital coupling.
  }
  the following Hamiltonian should be considered:
  \begin{align}
      H_{SO}= \lambda P\cdot (\bigtriangledown V \times \sigma)
      \label{eq:ch3.SO_coupling}
  \end{align}
  Here $P$ is the mechanical momentum operator, $\sigma$ is the
  three pauli spin matrix $(\sigma_x, \sigma_y, \sigma_z)$.
  
  The tight-binding version of this is too complicated to be presented
  here, it is on page 16, equation (3.20).

  One additional consideration is the Rashba spin-orbit coupling.
  This is the peculiar result of electrons trapped in a two
  dimensional surface. In the $Z$ direction, with $Z$ perpendicular
  to the 2 dimensional plane, the potential looks like something
  below, called a triangular potential:
  \begin{figure}[H]
      \centering
      \includegraphics[width=0.6\linewidth]{pics/{ch3.rashba_spin-orbit_effect}.png}
      \caption{Conduction band at the interface of a semiconductor 
          heterostructure. Band bending creates a potential well 
          $V(z)$ confining the electrons to the XY plane. The asymmetry 
          of this well leads to Rashba spin-orbit coupling.}
      \label{fig:ch3-orbit_effect.png}
  \end{figure}
  It is pretty obvious, by equation \ref{eq:ch3.SO_coupling}, that
  this potential is going into our Hamiltonian.
  The result in tight-binding model is yet another complicated
  Hamiltonian, not to be presented here, numbered equation (3.23)
  on page 18.

\section{Chapter 4 - Green’s function formalism}
\label{sec:Chapter_4-Greens_function_formalism}

In this section we finally circled back to the Landauer-Büttiker
formalism. Here a breif summary of chapter 3 and 4 is opportune.
The purpose of chapter 3 and 4 as a whole, is to calculate the 
transmission coefficient $T_{qp}$ in equation
\ref{eq:ch1.Landauer-Buttiker_formula}. Here, chapter 3 establish the
Hamiltonian, and chapter 4 uses the Green function to calculate
transmission coefficient out of the Hamiltonian.

  \subsection{4.1 Green’s functions: The basics}
  \label{sec:4.1_Greens_functions_The_basics}
  
  The author takes the definition of Green's function as inverse
  of Hamiltonian, more specifically:
  \begin{align}
      [E-\hat{H}]\hat{G}(E) = 1
  \end{align}
  or, in the position-spin representation:
  \begin{align}
      [E-H(\vec{x})]G(\vec{x},\vec{x'},E)=\delta(\vec{x}-\vec{x'})
  \end{align}
  where $\vec{x}=(\vec{r},\sigma)$, containing in addition to the
  usual spatial part, the spin part.

  The physical meaning is also explained, although I learnt this
  better in A. Zee's QFT in a Nutshell. However, he notes that
  to disguish between the source and sink, i.e. to tell whether
  the Green's function calculated represents a wavefunction
  resulted from a unit excitation (the sink), or a source for such
  an excitation, we should incorporate boundary conditions. This is
  done by adding "an infinitesimal imaginary variable into the energy",
  "leading to the following definitions":
  \begin{align}
      G^{\pm}(\vec{x},\vec{x'},E)\equiv \lim_{\eta\to 0^{+}}
          G(\vec{x},\vec{x'},E\pm i\eta)
  \end{align}
  and $G^{\pm}$ satisfies:
  \begin{align}
      [E\pm i\eta - H(\vec{x})] G^{\pm}(\vec{x},\vec{x'},E)=
          \sigma(\vec{x}-\vec{x'})
  \end{align}
  The functions $G^+$ and $G^-$ are called respectively the
  \textbf{retarded and advanced Green's function}. The author
  mentions that, "when Fourier transforming the functions $G^\pm$ to
  the time domain using a closed contour integration in the complex 
  plane, they would correspond to causal and anticausal solutions".

  Though seemingly extraneous, the operator definition for above
  Green functions is also mentioned:
  \begin{align}
      \hat{G}^{\pm}(E)\equiv \lim_{\eta\to 0^+}
          \frac{1}{E\pm i\eta-\hat{H}}
  \end{align}
  \subsection{4.2 Transmission coefficients and the Green’s function}
  \label{sec:4.2_Transmission_coefficients_and_the_Greens_function}
  
  Here it is mentioned than the transmission coefficient is related
  Green's funciton in the following way:
  \begin{align}
      T_{pq} = \text{Tr}\left[\Gamma_p G_{pq}\Gamma_q G^{\dagger}_{pq}
              \right]
  \end{align}
  Here $G_{pq}$ is, to borrow the language of matrix mechanics,
  a submatrix of the Green's function. $\Gamma_p$ is a abbreviation
  for the following counting:
  \marginpar{I am not sure about this peculiar thing.}
  \begin{align}
      \label{eq:}
      \Gamma_p \equiv i(\textstyle\sum_p-\textstyle\sum^\dagger_p)
  \end{align}
  Here $\sum_p$ is named "self-energy of the lead", something I
  don't quite understand.
  \subsection{4.3 Lattice Green’s function method}
  \label{sec:4.3_Lattice_Greens_function_method}
  In this section, the author builds up a recursive method to calculate
  the Green's function. The difficulty in calculating Green's function
  is that the Hamiltonian matrix might be infinite, hence impossible
  to invert numerically, or the inversion is numercially expensive.
  Hence a recursive method is more preferable.

  We define a notation for one particular submatrix of Green's funciton.
  $G_{nn'}$ is such that:
  \begin{align}
      \braket{m,\sigma|G_{nn'}(E)|m',\sigma'} 
          \equiv \braket{nm\sigma |G(E)|n'm'\sigma'}
          = G_{nm\sigma,n'm'\sigma'}(E)
  \end{align}
  where $(m,n)$ labels columns in the tight-binding lattice, 
  and $\sigma$ is the spin index.

    \subsubsection{4.3.1 Semiinfinite leads: Self-energy description}
    \label{sec:4.3.1_Semiinfinite_leads_Self-energy_description}
    We have the following Hamiltonian from Landauer-Büttiker 
    formalism,
    \begin{align}
        H= H_{cd} + \sum_i (H^i_l + V^i_{ld} + V^i_{dl})
        \label{eq:ch4.1.3_H_general}
    \end{align}
    
    where $H_{cd}$ is the Hamiltonian for the central device, and 
    $H_{li}$ the Hamiltonian for lead $i$. The coupling between 
    lead and device is described by $V_{ld}^i$ (and its hermitian
    conjugate $V_{dl}^i$ ). 

    Here is a improvement on that. 
    It is shown that the central device, including the influence of
    leads on it, is described by a \textit{finite-dimensional}
    Hamiltonian:
    \begin{align}
        \mathcal{H}_{cd} = H_{cd} + \sum_i \textstyle\sum^i
    \end{align}
    where $\sum^i$ is called the retarted self-energy of lead $i$:
    \begin{align}
        \textstyle\sum^i = V^i_{dl}g^i_l V^i_{ld}
    \end{align}
    Here $g^i_l$ is the Green's function of the isolated 
    semi-infinite lead: $g^i_l= [E+i\eta -H^i_l]^{-1}$.

    At this point, the problem of computation is finally solve 
    because we are using nearest neighbour model here. Hence the 
    dimension of some matrix is significantly cut down.
    \marginpar{
        Actually, I don't see why the dimension of matrix is infinite
        in the above \ref{eq:ch4.1.3_H_general}, while here the
        matrix suddenly become fininte.
    }
    Also, author mentions that several methods are available to
    calculate this Green's funciton: analytical solution when the
    magnetic field is absent; numerical methods when there is a
    magnetic field.

    \subsubsection{4.3.2 Recursive technique: Standard method}
    \label{sec:4.3.2_Recursive_technique_Standard_method}
    Recursive method is based on the Dyson's equation:
    \begin{align}
      \label{eq:4.3.2.Dyson_Equaton}
      \hat{G}=\hat{g}+ \hat{g} \hat{V}\hat{G}
    \end{align}
    (Note that this is an equation of operators!)

    Here $g$ is the Green's function of two disconnected subsystems,
    $G$ is the Green's funciton of the connected system,
    comprising two previously disconnected subsystems; $V$ describes
    the hopping between the subsystems. One may already see the
    spirit of recursive method, by that $G$ appears on both side
    of the equation.
    
    It should be noted that, strictly speaking, in Dyson's equation
    there should be two part: the self-energy part and everything
    else (categorized as external potential). But I am not confident
    about this.
    % TODO improve Dyson's equation.

    After this, the author illustrates one simple example of using
    Dyson's equation to calculate $G$. This process is essentially
    the same as the standard recursive technique. Therefore I will
    only mention the standard technique below.

    The standard technique is best illustrated with the following
    diagram:
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\linewidth]{pics/{ch4.3.standard_recursive_technique}.png}
        \caption{Standard recursive technique}
        %\label{fig:pics/ch4.standard_recursive_technique.png}
    \end{figure}

    And these equations:
    \begin{align}
        G^L_{n+1,n+1}=&
          \left(1-
            G^{isol}_{n+1,n+1}V_{n+1,n}G^L_{n,n}V_{n,n+1}\right)^{-1}
          G^{isol}_{n+1,n+1}
        \\
        G^L_{n+1,1}=& G^L_{n+1,n+1}V_{n+1,n}G^L_{n,1}
        \\
        G^L_{1,n+1} =& G^L_{1n} V_{n,n+1} G^L_{n+1,n+1}
    \end{align}

    \subsubsection{4.3.3 Recursive technique: An extension}
    \label{sec:4.3.3_Recursive_technique_An_extension}

    The author utilizes a simple bisection method to calculate,
    best illustrated by the diagram:
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\linewidth]{pics/{ch4.3.extended_recursive_technique}.png}
        \caption{Extended recursive technique}
        %\label{fig:pics/ch4.extended_recursive_technique.png}
    \end{figure}
    There is, obviously, one final step that requires different formula
    than the previous steps:
    \begin{align}
        G_{n1}=&
          \left( 1-G^L_{nn}V_{n,n+1}G^R_{n+1,n+1}V_{n+1,n}\right)^{-1}
          \cdot G^L_{n1}
        \\
        G_{1n}=&
          G^L_{1n}+G^L_{1n}V_{n,n+1}G^R_{n+1,n+1}V_{n+1,n}G_{nn}
        \\
        G_{nn}=&
          \left(1-G^L_{nn}V_{n,n+1}G^R_{n+1,n+1}V_{n+1,n}\right)^{-1}
          \cdot G^L_{nn}
        \\
        G_{Nn}=& G^R_{N,n+1}V_{n+1,n}G_{nn}
        \\
        G_{nN}=& G_{nn}V_{n,n+1}G^R_{n+1,N}
    \end{align}
\section{Anchor}

\begin{thebibliography}{1}
    \bibitem{dissertation} 
        \href{https://sundoc.bibliothek.uni-halle.de/diss-online/07/07H039/prom.pdf}{Electronic Transport in Mesoscopic Systems}, 
        by von Georgo Metalidis. (Link found via Google)
\end{thebibliography}
\printnomenclature
\section{License}
The entire content of this work (including the source code
for TeX files and the generated PDF documents) by 
Hongxiang Chen (nicknamed we.taper, or just Taper) is
licensed under a 
\href{http://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative 
Commons Attribution-NonCommercial-ShareAlike 4.0 International 
License}. Permissions beyond the scope of this 
license may be available at \url{mailto:we.taper[at]gmail[dot]com}.
\end{document}
