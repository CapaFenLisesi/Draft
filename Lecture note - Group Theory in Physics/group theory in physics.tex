% The entire content of this work (including the source code
% for TeX files and the generated PDF documents) by 
% Hongxiang Chen (nicknamed we.taper, or just Taper) is
% licensed under a 
% Creative Commons Attribution-NonCommercial-ShareAlike 4.0 
% International License (Link to the complete license text:
% http://creativecommons.org/licenses/by-nc-sa/4.0/).
\documentclass{article}

\usepackage{float}  % For H in figures
\usepackage{amsmath} % For math
\usepackage{amssymb}
\usepackage{mathrsfs}
% Followings are for the special character: differential "d".
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand*\Diff[1]{\mathop{}\!\mathrm{d^#1}}
\numberwithin{equation}{subsection} % have the enumeration go to the subsection level.
                                    % See:https://en.wikibooks.org/wiki/LaTeX/Advanced_Mathematics
\usepackage{graphicx}   % need for figures
\usepackage{cite} % need for bibligraphy.
\usepackage[unicode]{hyperref}  % make every cite a link
\usepackage{CJKutf8} % For Chinese characters
\usepackage{fancyref} % For easy adding figure,equation etc in reference. Use \fref or \Fref instead of \ref
\usepackage{braket} %http://tex.stackexchange.com/questions/214728/braket-notation-in-latex

% Following is for theorems etc environments
% http://tex.stackexchange.com/questions/45817/theorem-definition-lemma-problem-numbering && https://en.wikibooks.org/wiki/LaTeX/Theorems
\usepackage{amsthm}
\newtheorem{defi}{Definition}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{coro}{Corollary}[section]
\theoremstyle{definition}
\newtheorem{ex}{Example}[section]
\newtheorem{fact}{Fact}[section]

\usepackage{CJKutf8} % For chinese characters.
% A list of nomenclatures.
\usepackage{nomencl}
\makenomenclature

% For highlighting
\usepackage{xcolor,soul}
\newcommand{\hlMath}[1]{\colorbox{yellow!80}{$\displaystyle#1$}}


\title{Group Theory in Physics (Course Note)}
\date{\today}
\author{Taper}


\begin{document}


\maketitle
\abstract{
This is our course note for the course about group theoy, with its
application in physics.
}
\tableofcontents
\begin{enumerate}
    \item Combine group theory with you research.
    \item Mid-term and final.
    \item No homework, cause it is already graduate level.
    \item Professor Fei Ye. (Phone: 88018229, 228 in Research building 2), 
        T.A. Zhe Zhang. (110 Research building 2).
\end{enumerate}

\section{20160919}
\label{sec:20160919}

He first introduces several common examples of symmetries in our life and
physics. Omitted, with one exception:

He mentions that there is one more symmetry in the Hydrogen 
Hamiltonian: the Laplace-Runge-Lenz symmetry. (So its symmetry 
group is not just $SO(3)$, but two copies of $SO(3)$ that forms a $SO(4)$.
And using the representation of $SO(4)$, the complete spectrum of
Hydrogen Hamiltonian is solved. Hence this $SO(4)$ is the largest
symmetry of Hydrogen Hamiltonian.

    \subsection{Digression about Lenz vector}
    \label{sec:Digression_about_Lenz_vector}
    Since the class is too boring, I checked about the Lenz vector via
    Google and found this Math.SE question \cite{math.se_1_lenz_vector}

    The first answer to that post is:

    \begin{center}\noindent\rule{8cm}{0.4pt}\end{center}

    \begin{quote}
        1) \textbf{Problem}. The \href{http://en.wikipedia.org/wiki/Kepler_problem}{Kepler Problem} has Hamiltonian

        $$ H~:=~ \frac{p^2}{2m}- \frac{k}{q},  $$

        where $m$ is the 2-body reduced mass. The [Laplace–Runge–Lenz vector](http://en.wikipedia.org/wiki/Laplace%E2%80%93Runge%E2%80%93Lenz_vector) is (up to an irrelevant normalization)

        $$ A^j ~:=~a^j  + km\frac{q^j}{q}, \qquad a^j~:=~({\bf L} \times {\bf p})^j~=~{\bf q}\cdot{\bf p}~p^j- p^2~q^j,\qquad {\bf L}~:=~ {\bf q} \times {\bf p}.$$ 

        2) \textbf{Action}. The Hamiltonian Lagrangian is

        $$  L_H~:=~ \dot{\bf q}\cdot{\bf p} - H, $$

        and the action is 

        $$ S[{\bf q},{\bf p}]~=~ \int {\rm d}t~L_H .$$

        The non-zero fundamental canonical Poisson brackets are 

        $$ \{ q^i , p^j\}~=~ \delta^{ij}. $$

        3) \textbf{Inverse Noether's Theorem}. Quite generally in the Hamiltonian formulation, given a constant of motion $Q$, then the infinitesimal variation 

        $$\delta~=~ \varepsilon \{Q,\cdot\}$$ 

        is a global off-shell symmetry of the action $S$ (modulo boundary terms). Here $\varepsilon$ is an infinitesimal global parameter, and $X_Q=\{Q,\cdot\}$ is a Hamiltonian vector field with Hamiltonian generator $Q$. The full Noether current is (minus) $Q$, see e.g. my answer to [this question](http://physics.stackexchange.com/q/8626/2451). \hl{(The words \textbf{on-shell}. and \textbf{off-shell}. refer to whether the equations of motion are satisfied or not.)}

        4) \textbf{Variation}. Let us check that the three Laplace–Runge–Lenz components $A^j$ are Hamiltonian generators of three continuous global off-shell symmetries of the action $S$. In detail, the infinitesimal variations $\delta= \varepsilon_j \{A^j,\cdot\}$ read

        $$ \delta  q^i ~=~  \varepsilon_j  \{A^j,q^i\}   , \qquad 
         \{A^j,q^i\} ~ =~ 2 p^i q^j - q^i p^j - {\bf q}\cdot{\bf p}~\delta^{ij}, $$
        $$ \delta  p^i ~=~  \varepsilon_j  \{A^j,p^i\}   , \qquad  
        \{A^j,p^i\}~ =~ p^i p^j - p^2~\delta^{ij} +km\left(\frac{\delta^{ij}}{q}- \frac{q^i q^j}{q^3}\right), $$
        $$ \delta  t ~=~0,$$

        where $\varepsilon_j$ are three infinitesimal parameters.

        5) Notice for later that

        $$ {\bf q}\cdot\delta {\bf q}~=~\varepsilon_j({\bf q}\cdot{\bf p}~q^j - q^2~p^j),  $$

        $$ {\bf p}\cdot\delta {\bf p}
        ~=~\varepsilon_j km(\frac{p^j}{q}-\frac{{\bf q}\cdot{\bf p}~q^j}{q^3})~=~- \frac{km}{q^3}{\bf q}\cdot\delta {\bf q},  $$

        $$ {\bf q}\cdot\delta {\bf p}~=~\varepsilon_j({\bf q}\cdot{\bf p}~p^j - p^2~q^j )~=~\varepsilon_j a^j,  $$

        $$ {\bf p}\cdot\delta {\bf q}~=~2\varepsilon_j( p^2~q^j - {\bf q}\cdot{\bf p}~p^j)~=~-2\varepsilon_j a^j~.  $$

        6) The Hamiltonian is invariant

        $$ \delta  H ~=~ \frac{1}{m}{\bf p}\cdot\delta {\bf p} + \frac{k}{q^3}{\bf q}\cdot\delta {\bf q}~=~0, $$

        showing that the Laplace–Runge–Lenz vector $A^j$ is classically a constant of motion 

        $$\frac{dA^j}{dt} ~\approx~ \{ A^j, H\}+\frac{\partial A^j}{\partial t} ~=~  0.$$   

        (We will use the $\approx$ sign to stress that an equation is an on-shell equation.) 

        7) The variation of the Hamiltonian Lagrangian $L_H$ is a total time derivative

        $$ \delta L_H~=~ \delta  (\dot{\bf q}\cdot{\bf p})~=~ \dot{\bf q}\cdot\delta {\bf p} - \dot{\bf p}\cdot\delta {\bf q} + \frac{d({\bf p}\cdot\delta {\bf q})}{dt} $$
        $$  =~ \varepsilon_j\left( \dot{\bf q}\cdot{\bf p}~p^j - p^2~\dot{q}^j +  km\left( \frac{\dot{q}^j}{q} -  \frac{{\bf q} \cdot \dot{\bf q}~q^j}{q^3}\right)\right)    $$
        $$- \varepsilon_j\left(2 \dot{\bf p}\cdot{\bf p}~q^j - \dot{\bf p}\cdot{\bf q}~p^j- {\bf p}\cdot{\bf q}~\dot{p}^j  \right) - 2\varepsilon_j\frac{da^j}{dt}$$
        $$ =~\varepsilon_j\frac{df^j}{dt}, \qquad f^j ~:=~ A^j-2a^j, $$

        and hence the action $S$ is invariant off-shell up to boundary terms.

        8) \textbf{Noether current}. The bare \href{http://en.wikipedia.org/wiki/Noether%27s_theorem}{Noether current} $j^k$ is

        $$j^k~:=~ \frac{\partial L_H}{\partial \dot{q}^i}  \{A^k,q^i\}+\frac{\partial L_H}{\partial \dot{p}^i}  \{A^k,p^i\}
        ~=~ p^i\{A^k,q^i\}~=~ -2a^k. $$

        The full Noether current $J^k$ (which takes the total time-derivative into account) becomes (minus) the Laplace–Runge–Lenz vector

        $$ J^k~:=~j^k-f^k~=~ -2a^k-(A^k-2a^k)~=~ -A^k.$$

        $J^k$ is conserved on-shell 

        $$\frac{dJ^k}{dt} ~\approx~  0,$$  

        due to \href{http://en.wikipedia.org/wiki/Noether%27s_theorem}{Noether's first Theorem}. Here $k$ is an index that labels the three symmetries.
    \end{quote}

    \begin{center}\noindent\rule{8cm}{0.4pt}\end{center}

    However, I don't really understand the content inside. I asked professor
    Ye whether we can find some physics about this conserved quantity, and
    he answered with no.

    The next answer is also interesting:
    
    \begin{center}\noindent\rule{8cm}{0.4pt}\end{center}

    \begin{quote}
        While Kepler second law is simply a statement of the conservation of angular momentum (and as such it holds for all systems described by central forces), \hl{the first and the third laws are special and are linked with the unique form of the newtonian potential $-k/r$.} In particular, \hl{Bertrand theorem assures that *only* the newtonian potential and the harmonic potential $kr^2$ give rise to closed orbits (no precession).} It is natural to think that this must be due to some kind of symmetry of the problem. In fact, the particular symmetry of the newtonian potential is described exactly by the conservation of the RL vector (\hl{it can be shown that the RL vector is conserved iff the potential is central and newtonian}). This, in turn, is due to a more general symmetry: \hl{if conservation of angular momentum is linked to the group of special orthogonal transformations in 3-dimensional space $SO(3)$, conservation of the RL vector must be linked to a 6-dimensional group of symmetries}, since in this case there are apparently six conserved quantities (3 components of $L$ and 3 components of $\mathcal A$). In the case of bound orbits, this group is $SO(4)$, the group of rotations in 4-dimensional space.  

        Just to fix the notation, the RL vector is:

        \begin{equation} \mathcal{A}=\textbf{p}\times\textbf{L}-\frac{km}{r}\textbf{x} \end{equation}

        Calculate its total derivative:

        \begin{equation}\frac{d\mathcal{A}}{dt}=-\nabla U\times(\textbf{x}\times\textbf{p})+\textbf{p}\times\frac{d\textbf{L}}{dt}-\frac{k\textbf{p}}{r}+\frac{km(\textbf{p}\cdot \textbf{x})}{r^3}\textbf{x} \end{equation}

        Make use of Levi-Civita symbol to develop the cross terms:

        \begin{equation}\epsilon_{sjk}\epsilon_{sil}=\delta_{ji}\delta_{kl}-\delta_{jl}\delta_{ki}   \end{equation}

        Finally:

        \begin{equation}
        \frac{d\mathcal{A}}{dt}=\left(\textbf{x}\cdot\nabla U-\frac{k}{r}\right)\textbf{p}+\left[(\textbf{p}\cdot\textbf{x})\frac{k}{r^3}-2\textbf{p}\cdot\nabla U\right]\textbf{x}+(\textbf{p}\cdot\textbf{x})\nabla U
        \end{equation}

        Now, if the potential $U=U(r)$ is central:

        \begin{equation}
        (\nabla U)_j=\frac{\partial U}{\partial x_j}=\frac{dU}{dr}\frac{\partial r}{\partial x_j}=\frac{dU}{dr}\frac{x_j}{r}
        \end{equation}

        so 

        \begin{equation} \nabla U=\frac{dU}{dr}\frac{\textbf{x}}{r}\end{equation}

        Substituting back:

        \begin{equation}
            \hlMath{\frac{d\mathcal A}{dt}=\frac{1}{r}\left(\frac{dU}{dr}-\frac{k}{r^2}\right)[r^2\textbf{p}-(\textbf{x}\cdot\textbf{p})\textbf{x}]}
        \end{equation}

        Now, you see that if $U$ has \textit{exactly} the newtonian form then the first parenthesis is zero and so the RL vector is conserved. 

        Maybe there's some slicker way to see it (Poisson brackets?), but this works anyway.
    \end{quote}
    \begin{center}\noindent\rule{8cm}{0.4pt}\end{center}
    
    % TODO Study in detail about this example.

    \subsection{Coming back to the course}

After mentioning the Poinc\'{a}re group, he produces to review some
concepts about linear algebra:
\begin{enumerate}
    \item The axioms of linear space, using quantum mechanics
        as basic example (Omitted).
    \item Some common concepts of linear space: linear-independence,
        subspace, direct sum, linear operators, its matrix representation. (Omitted)
    \item Introducing the complete antisymmetric tensor 
        $\epsilon^{a_1,\cdots,a_n}$. Some properties:
        \begin{align}
            \frac{1}{(m-n)!} \sum_{a_{n+1},\cdots, a_m}
            & \epsilon_{a_1,\cdots,a_n,a_{n+1},a_m}
            \epsilon_{b_1,\cdots,b_n,a_{n+1},a_m}\nonumber
            \\
            &= \sum_{p_1,\cdots,p_n} 
            \epsilon_{p_1,\cdots,p_n} 
                \delta_{a_1,b_{p_1}}\cdots \delta_{a_n,b_{p_n}}
                \\
            \epsilon_{ab}\epsilon_{rs} &=
                \delta_{ar}\delta_{bs}-\delta_{as}\delta_{br}
                \\
            \sum_d\epsilon_{abd}\epsilon_{rsd} &=
                \delta_{ar}\delta_{bs} + \delta_{as}\delta_{br}
        \end{align}
    \item Some special matrices.
    \item Fact: If $R\Gamma = \Gamma R$, and 
        $\Gamma$ is diagonal. (let $\mu\neq\nu$) Then if 
        $\Gamma_{\mu\mu} \neq \Gamma_{\nu\nu}$ , we have:
        $ R_{\mu\nu}=R_{\nu\mu} = 0 $.
        On the other hand, if $R_{\mu\nu}\neq 0$, then
        $\Gamma_{\mu\mu}=\Gamma_{\nu\nu}$.
        This is obviously from:
        \begin{align*}
            \sum_j R^{i}_{j}\Gamma^{j}_{k}=\sum_j\Gamma^{i}_{j} R^{j}_k
            \Longrightarrow
            R^i_k\Gamma^k_k = \Gamma^i_i R^i_k
        \end{align*}
        where the first is automatically summed, and the second is not.

    \item A linear functional is closed w.r.t. a vector space. (Omitted)
    \item ... then this linear functional can be expressed as a
        matrix w.r.t to a basis of this vector space. (Omitted)
    \item Invariant subspace. (Omitted)
    \item Transformation of basis. (Omitted)
    \item Direct sum of operators:

        Let vector spaces $L=L_1\oplus L_2$, with $L=\braket{e_i}$,
        $L_1=\braket{e'_1,\cdots e'_n}$,$L_2=\braket{e'_{n+1},\cdots,e'_m}$,
        $e'_\nu=\sum_\mu e_\mu  S_{\mu\nu}$. 
        Assume that $L_1,L_2$ are invariant w.r.t $A$, an linear operator. If:
        \begin{align}
            A e'_\mu = \sum_{\nu=1}^{m} e'_\nu R'_{\nu\mu}
        \end{align}
        we have obviously:
        \begin{align}
            A e'_\mu = \sum_{\nu=1}^{n} e'_\nu R'_{\nu\mu} \text{for }
                \mu\in \{1\cdots n\}
                \\
            A e'_\mu = \sum_{\nu=n}^{m} e'_\nu R'_{\nu\mu} \text{for }
                \mu\in \{n\cdots m\}
        \end{align}
        i.e., $A$'s matrix representation has two diagonal blocks.
        Using this fact, $A$ after a linear transformation (by $S$),
        could be written as $R_1\oplus R_2$, where the meaning of $R_1/R_2$
        is obvious.
    \item Eigenvalues and the characteristic equation. (Omitted)
        Some properties:
        \begin{enumerate}
            \item Trace = $\sum_i \lambda_i$
            \item Determinant = $\prod_i \lambda_i$
            \item Geometric multiplicity $\leq$ Algebraic multiplicity, or
                $$\mathrm{dim}V_{\lambda_1} \leq n_1$$.
        \end{enumerate}
    \item Inner product and orthonormal basis. (Omitted) Here we define
        matrix $\Omega$ to be, when a basis $\{e_i\}$is given:
        \begin{defi}[]
        \nomenclature{}{\nomrefpage.}
            \begin{align}
                \Omega_{ij} \equiv \braket{e_i,e_j}
            \end{align}
        \end{defi}
    \item Adjoint operator:

        Let $A$ be a linear operator represented by matrix $A^i_j$. Let
        its adjoint $A^\dagger$ be represented by $R^i_J$. Then using
        $\braket{A^\dagger e_j, e_i} = \braket{e_j,A e_i}$, we will
        get $(R^{k}_j)^* \Omega_{ki}= \Omega_{jk}A^k_i$, i.e.
        $(R^T)^* \Omega = \Omega A$, so:
        \begin{align}
            R = \Omega^{-1} A^\dagger \Omega
        \end{align}
        where we have used the fact that $\Omega^\dagger=\Omega$.

        Note that $(R^{k}_j)^* \Omega_{ki}$ is not $\Omega^T R^*$.
        (Be careful and you will find out why.)

        This is very different from my previous naive concept
        when $\Omega$ is not identity matrix, i.e. when the basis
        is not orthonormal.
\end{enumerate}

\section{20160926}
\label{sec:20160926}

He first introduces some important matrices:

\paragraph{Unitary matrix} Eigenvalues of Unitary matrices has modulus $1$,
i.e. $|\lambda|=1$. This can be proved directly. Also, Unitary matrices are unitarily diagonalizable. This is a result of the following Spectral Theorem:
\begin{thm}[Spectral Theorem]
    A matrix $A$, which is normal (i.e. $A^\dagger A= AA^\dagger$), if and only if it is unitarily diagonalizable.
\end{thm}
\begin{proof}
    If $A$ is normal, then by Schur decomposition, we can write
    $A=UTU^\dagger$, here $U$ is unitary and $T$ is upper-triangular. 
    Using the condition of being normal, one can show directly that $T$ 
    is in fact also normal. Now we show that any triangular matrix that 
    is normal must be diagonal. Observe that we have 
    $\braket{e_i,T^\dagger T e_i}=\braket{e_i,TT^\dagger e_i}$, 
    i.e. $\braket{T^\dagger e_i, T^\dagger e_i}=\braket{T e_i, T e_i}$. 
    This is sayin g that the norm of the first column of $A^\dagger$ 
    is equal to the norm of the first column of $A$. Obviously 
    $A$ has to be diagonal.

    The converse is obvious.
\end{proof}

Also, unitary matrix's eigenvector corresponding to different eigenvalues 
are orthogonal. This is a direct result of fact mentioned above.

\paragraph{Hermitian matrices} They have real eigenvalues and orthogonal
eigenvectors (proof omitted). Also, if $\text{det}(R^\dagger R)\neq 0$,
then $R^\dagger R >0$, i.e. it is positive-definite. 

\textbf{This is wong:} An example is that
the matrix $\Omega$ introduced in the previous lecture has
$\text{det}(\Omega^\dagger \Omega)=\text{det}(\Omega)$, hence
$\text{det}(\Omega)=1$ (it cannot be $0$), hence it is positive definite.

\textbf{Actually} 
$\text{det}(\Omega^\dagger \Omega)\neq\text{det}(\Omega)$, because
\begin{align}
    \sum_\rho \ket{e_\rho}\bra{e_\rho} \neq 1 \text{(unless the basis is
        orthonormal)}
    % TODO think about this in depth
\end{align}
Therefore we need anthoer argument for $\Omega$ being positive-definite.
It is provided in page 11 of \cite{book}.

\paragraph{Orthogonal matrix} For an orthogonal matrix over $\mathbb{C}$,
it is quite troublesome. For example, if $Ra=\lambda a$ and
$\lambda \neq \pm 1$, then we have $a^T a=0$, which is quite bad because
this force $a$ to have complex components.

\paragraph{Orthogonal matrix over $\mathbb{R}$} In this case, we have
similar result. But it is easy to show that for an orthogonal matrix
$R$ having only real elements, then its eigenvalues $\lambda= \pm 1$.

Then he proceeds to direct product.
\paragraph{Direct product} and also the Kronecker Product of two
matrices. Properties (let $T=R\otimes S$):
\begin{enumerate}
    \item $\mathrm{dim}T = \mathrm{dim}R \times \mathrm{dim}S$
    \item $\mathrm{tr}(T)=\mathrm{tr}(R)\mathrm{tr}(S)$
    \item $\otimes$ commutes with the operation of inverse, transpose,
        and transpose conjugation.
    \item \begin{align}
            \frac{d}{d\alpha} (R(\alpha)\otimes S(\alpha)) =
            R'(\alpha)\otimes S(\alpha) + R(\alpha)\otimes S'(\alpha)
    \end{align}
    \item when the dimentions are the same:
        \begin{enumerate}
            \item 
            $(R_1\otimes S_1)(R_2\otimes S_2) = (R_1R_2)\otimes (S_1S_2)$
        \end{enumerate}
\end{enumerate}

Finally we arrived in the group theory.
\paragraph{Symmetry examples} Dipole transition. 
$\braket{\phi_f|\hat{P}|\phi_i}$, must happen when the parity of $\phi_i$
and $\phi_f$ is of opposite parity. (pp.18 of \cite{book})

\paragraph{Group}
\begin{defi}[Group]
\nomenclature{Group}{\nomrefpage.}
    Omitted.
\end{defi}
Some basic properties (Omitted).
\begin{defi}[Abel Group]
\nomenclature{Abel Group}{\nomrefpage.}
    Omitted.
\end{defi}
\begin{defi}[Cardinality of group $\# A$]
\nomenclature{Cardinality of group $#$}{\nomrefpage.}
    Omitted.
\end{defi}

\paragraph{Multiplication table}

Facts: group of order $1,2,$ and $3$ are unique up to an isomorphism.

\begin{defi}[Cyclic group, generators]
\nomenclature{Cyclic group, generators}{\nomrefpage.}
    Omitted.
\end{defi}

\begin{CJK}{UTF8}{gbsn}
固有转动是指的那些 $det(M)>0$ 的转动. 用$C_n$来表示他们.

Also, 周期 of $R$ is just $\braket{R}$.
\end{CJK}

Let $\sigma$\nomenclature{$\sigma$}{\nomrefpage.} for spatial reflection.
\begin{defi}[$C_N,\bar{C}_N$]
\nomenclature{$C_N,\bar{C}_N$}{\nomrefpage.}
    $\bar{C}_N=C_N*\sigma$
\end{defi}
\section{20161010}
\label{sec:20161010}
Introducing to various groups:$S_4, V_4$, $D_3$, all omited.
(\textbf{pp.22-23 of \cite{book}})

$D_n$ group. See pp. 25-26 of the book \cite{book}.
Note that here the $n$ refers to the $n$-polygon, not that the group is
of order $n$. For the mathematicians, they might be comfortable with
$D_n$ means the dihedral group of order $n$, but is actually the group of
symmetries of $n/2$-polygon.

\begin{defi}[Subgroup]
\nomenclature{Subgroup}{\nomrefpage.}
    Omitted.
\end{defi}
\begin{fact}
    One only has to check the closeness for determining a subgroup, if it
    is of finite order.

    However, for group of infinite order, one has to check the existance
    of unit and inverse elements.
\end{fact}
Examples of subgroup (\textbf{pp.26 of \cite{book}})

Noteworth:$C_6$ has three copies of $D_2$, this can be intuitively 
guessed by the fact that a hexago has three rectanle in it.

\begin{defi}[Coset]
\nomenclature{Coset}{\nomrefpage.}
    Omitted.
\end{defi}
Properties of coset (omitted).

\begin{defi}[Index of subgroup]
\nomenclature{Index of subgroup}{\nomrefpage.}
    Omitted.
\end{defi}

\begin{prop}
    Two elements $R$ and $T$ belongs to the same coset $kH$, if and only
    if $R^{-1}T\in H$.
\end{prop}
\begin{proof}
    Omitted.
\end{proof}
\begin{defi}[Normal/Invariant subgroup]
\nomenclature{Normal/Invariant subgroup}{\nomrefpage.}
    A subgroupNormal/Invariant subgrouproup(also invariant), if and only
    if for any $x\in G$, we have $xH = Hx$.
\end{defi}
\begin{fact}
    If $H$ has index 2, then it must be normal/invariant. This is
    obvious.
\end{fact}
\begin{defi}[Quotient]
\nomenclature{Quotient}{\nomrefpage.}
    Omitted.
\end{defi}
Note that quotient group (a.k.a. factor group) is only defined for a normal subgroup.

\begin{ex}
    $D_3$ (Using the multiplication table). Omitted because it is too
    complex to be typed down here.
\end{ex}

\begin{defi}[Conjugate]
\nomenclature{Conjugate}{\nomrefpage.}
    If exists $S\in G$, s.t. $R' = S^{-1}RS$, then we say $R'$ is
    conjugate to $R$.
\end{defi}
see (\textbf{pp.28-30 of \cite{book}})
This is clearly an equivalence relationship. By this we can define
conjugate class, denoted by $C=\{R_1,\cdots\}$, then we have the
characterization $C = \{ s^{-1} R_i s|\forall s\in G\}$, for any
$R_i$. We then have the following facts (all are obvious):
\begin{fact}$ $

    \begin{enumerate}
        \item The unit class formed just by the unit element.
        \item The inverse class formed by just all the inverse element.
            $C^{-1} = \{ R_i^{-1}\}$. If $C=C^{-1}$, then $C$ is called
            self-inverse.
        \item The order of elements in a class is just the same.
        \item For $\forall T,S\in G$, $TS$ and $ST$ are conjugate to each
            other. This means that all elements symmetric on the
            multiplication table is conjugate to each other.
        \item For two elements $R$, $R'$ conjugate to each other, both
            can be expressed by the products of two elements in two
            different way. (Isn't this too obvious to mention.)
        \item Let $G$ be a rotation group. Suppose it has an axis of the
            order of $n$, with its operation denoted as $R$,, we can get
            a new axis by the following steps. (Supose we have another
            rotation $S$),

            \begin{enumerate}
                \item  $S^{-1}$, rotate $m$ back to $n$.
                \item  $R$, rotate about n around $2\pi/n$,
                \item  $S$ rotate $n$ to $m$
            \end{enumerate}

            Result: $S^{-1}RS$ rotate around a new axis $m$ about
            $2\pi/n$. So $R'=S^{-1}RS$ and $R$ is calle the equivalent
            axis. 
            
            Also, if $m=-n$, then they are called polar axis to each
            other.

        \item $C_n$, which is an abel group, every element form a
            conjugate class by itself. Specifically, $e$ and $R^{n/2}$
            are self inverse, if $n$ is even.
    \end{enumerate}
\end{fact}
\begin{prop}
    \label{prop:20161010.conjugate_subgroup}
    For an invariant subgroup, then every conjugate element is also
    inside the same invariant subgroup. This shows that an invariant
    subgroup can be decomposed into a series of sum of conjugate classes.
\end{prop}
\begin{proof}
    If $R\in H$, then we show that $S^{-1}RS\in H$, this is obviously
    since it belongs to $S^{-1}HS$.
\end{proof}

\begin{ex}
    For $D_3: E,D,F,A,B,C$, their orders are respetively
    $1,3,3,2,2,2$. We have the following conjugate classes:
    \begin{enumerate}
        \item $\{ E\}$. Is self inverse.
        \item $\{ D,F\}$. $D$ is conjugate to $F$. We can see
            this physically by looking at rotation from the front
            or the below. This class is also self-inverse.
        \item $\{A,B,C\}$, is clearly a self-inverse conjugate
            class.
    \end{enumerate}
\end{ex}
\begin{ex}[$D_6$]
    Ramiliarize one with the formulae for $D_n$. Hint: use the order of
    elements to find classes of conjugate. Then use the proposition
    \ref{prop:20161010.conjugate_subgroup} to find the subgroups.
    % TODO maybe I can try this when I am free.
\end{ex}





\section{Anchor}
\label{sec:Anchor}
\begin{thebibliography}{1}
    %\bibitem{book} 
    \bibitem{book} Zhongqi Ma, Group Theory in Physics
    \bibitem{math.se_1_lenz_vector} \href{physics.stackexchange.com/questions/18088/what-symmetry-causes-the-runge-lenz-vector-to-be-conserved}{What symmetry causes the Runge-Lenz vector to be conserved?}
\end{thebibliography}
\printnomenclature
\section{License}
The entire content of this work (including the source code
for TeX files and the generated PDF documents) by 
Hongxiang Chen (nicknamed we.taper, or just Taper) is
licensed under a 
\href{http://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative 
Commons Attribution-NonCommercial-ShareAlike 4.0 International 
License}. Permissions beyond the scope of this 
license may be available at \url{mailto:we.taper[at]gmail[dot]com}.
\end{document}
